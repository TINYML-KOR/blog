<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Seunghyun Oh">
<meta name="dcterms.date" content="2024-01-28">
<meta name="description" content="Pruning and Sparsity (Part I)">

<title>TinyML KOR - ğŸ§‘â€ğŸ« Lecture 3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">TinyML KOR</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">TinyML Study Group</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-to-pruning" id="toc-introduction-to-pruning" class="nav-link active" data-scroll-target="#introduction-to-pruning">1. Introduction to Pruning</a></li>
  <li><a href="#determine-the-pruning-granularity" id="toc-determine-the-pruning-granularity" class="nav-link" data-scroll-target="#determine-the-pruning-granularity">2. Determine the Pruning Granularity</a>
  <ul class="collapse">
  <li><a href="#pattern-based-pruning" id="toc-pattern-based-pruning" class="nav-link" data-scroll-target="#pattern-based-pruning">2.1 Pattern-based Pruning</a></li>
  <li><a href="#channel-level-pruning" id="toc-channel-level-pruning" class="nav-link" data-scroll-target="#channel-level-pruning">2.2 Channel-level Pruning</a></li>
  </ul></li>
  <li><a href="#determine-the-pruning-criterion" id="toc-determine-the-pruning-criterion" class="nav-link" data-scroll-target="#determine-the-pruning-criterion">3. Determine the Pruning Criterion</a>
  <ul class="collapse">
  <li><a href="#select-of-synapses" id="toc-select-of-synapses" class="nav-link" data-scroll-target="#select-of-synapses">3.1 <strong>Select of Synapses</strong></a></li>
  <li><a href="#select-of-neurons" id="toc-select-of-neurons" class="nav-link" data-scroll-target="#select-of-neurons">3.2 <strong>Select of Neurons</strong></a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">4. Discussion</a></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference">5. Reference</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ğŸ§‘â€ğŸ« Lecture 3</h1>
  <div class="quarto-categories">
    <div class="quarto-category">pruning</div>
    <div class="quarto-category">lecture</div>
  </div>
  </div>

<div>
  <div class="description">
    Pruning and Sparsity (Part I)
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Seunghyun Oh </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 28, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<style>
p {
  line-height: 2; /* Adjust the line-height property as needed */
  text-align: justify;
  text-justify: inter-word; /* Adjust the justification mode as needed */
}

.image-container {
  text-align: center; /* Center-align the contents horizontally */
}

.centered-text {
  text-align: center; /* Center-align the text within the container */
}
</style>
<p>ì•ìœ¼ë¡œ ì´ 5ì¥ì— ê±¸ì³ì„œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ë²•ë“¤ì— ëŒ€í•´ì„œ ì†Œê°œí•˜ë ¤ê³  í•œë‹¤. ê²½ëŸ‰í™” ê¸°ë²•ìœ¼ë¡œëŠ” Pruning, Quantization, Neural Network Architecture Search, Knowledge Distillation, ê·¸ë¦¬ê³  Tiny Engineì—ì„œ ëŒë¦¬ê¸° ìœ„í•œ ë°©ë²•ì„ ì§„í–‰í•  ì˜ˆì •ì¸ë° ë³¸ ë‚´ìš©ì€ <strong>MITì—ì„œ Song Han êµìˆ˜ë‹˜ì´ Fall 2022ì— í•œ ê°•ì˜ TinyML and Efficient Deep Learning Computing 6.S965</strong>ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¬ì •ë¦¬í•œ ë‚´ìš©ì´ë‹¤. ê°•ì˜ ìë£Œì™€ ì˜ìƒì€ ì´ <a href="https://efficientml.ai">ë§í¬</a>ë¥¼ ì°¸ì¡°í•˜ì!</p>
<p>ì²« ë²ˆì§¸ ë‚´ìš©ìœ¼ë¡œ <strong>â€œê°€ì§€ì¹˜ê¸°â€</strong>ë¼ëŠ” ì˜ë¯¸ë¥¼ ê°€ì§„ <strong>Pruning</strong>ì— ëŒ€í•´ì„œ ì´ì•¼ê¸°, ì‹œì‘!</p>
<section id="introduction-to-pruning" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-pruning">1. Introduction to Pruning</h2>
<p><strong>Pruning</strong>ì´ë€ ì˜ë¯¸ì²˜ëŸ¼ Neural Networkì—ì„œ ë§¤ê°œë³€ìˆ˜(ë…¸ë“œ)ë¥¼ ì œê±°í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì´ëŠ” Dropoutí•˜ê³  ë¹„ìŠ·í•œ ì˜ë¯¸ë¡œ ë³¼ ìˆ˜ ìˆëŠ”ë°, Dropoutì˜ ê²½ìš° ëª¨ë¸ í›ˆë ¨ ë„ì¤‘ ëœë¤ì ìœ¼ë¡œ íŠ¹ì • ë…¸ë“œë¥¼ ì œì™¸ì‹œí‚¤ê³  í›ˆë ¨ì‹œì¼œ ëª¨ë¸ì˜ Robustnessë¥¼ ë†’ì´ëŠ” ë°©ë²•ìœ¼ë¡œ í›ˆë ¨ì„ í•˜ê³ ë‚˜ì„œë„ ëª¨ë¸ì˜ ë…¸ë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ê°€ ëœë‹¤. ë°˜ë©´ Pruningì˜ ê²½ìš° í›ˆë ¨ì„ ë§ˆì¹œ í›„ì—, íŠ¹ì • Threshold ì´í•˜ì˜ ë§¤ê°œë³€ìˆ˜(ë…¸ë“œ)ì˜ ê²½ìš° ì‹œ Neural Networkì—ì„œ ì œì™¸ì‹œì¼œ ëª¨ë¸ì˜ í¬ê¸°ë¥¼ ì¤„ì´ë©´ì„œ ë™ì‹œì— ì¶”ë¡  ì†ë„ ë˜í•œ ë†’ì¼ ìˆ˜ ìˆë‹¤.</p>
<p><span class="math display">\[
\underset{W_p}{argmin}\ L(x;W_p), \text{ subject to } \lvert\lvert W_p\lvert\lvert_0\ &lt; N
\]</span></p>
<ul>
<li><strong>L represents the objective function for neural network training</strong></li>
<li><span class="math inline">\(x\)</span> is input<strong>, <span class="math inline">\(W\)</span></strong> is original weights<strong>, <span class="math inline">\(W_p\)</span></strong> is pruned weights</li>
<li><span class="math inline">\(\lvert\lvert W_p\lvert\lvert_0\)</span> calcuates the #nonzeros in <span class="math inline">\(W_p\)</span> and <span class="math inline">\(N\)</span> is the target #nonzeros</li>
</ul>
<p>ì´ëŠ” ìœ„ì™€ ê°™ì€ ì‹ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. íŠ¹ì • W ì˜ ê²½ìš° 0 ìœ¼ë¡œ ë§Œë“¤ì–´ ë…¸ë“œë¥¼ ì—†ì• ëŠ” ê²½ìš°ë¼ê³  ë³¼ ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤. ê·¸ë ‡ê²Œ Pruningí•œ Neural NetworkëŠ” ì•„ë˜ ê·¸ë¦¼ ì²˜ëŸ¼ ëœë‹¤.</p>
<div style="text-align: center;">
<img src="../../images/lec03/Untitled.png" class="img-fluid">
<p style="text-align: center;">
Reference. MIT-TinyML-lecture03-Pruning-1
</p>
</div>
<p>ê·¸ëŸ¼ ì™œ Pruningì„ í•˜ëŠ” ê±¸ê¹Œ? ê°•ì˜ì—ì„œ Pruningì„ ì‚¬ìš©í•˜ë©´ Latency, Memeoryì™€ ê°™ì€ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ë³´í•  ìˆ˜ ìˆë‹¤ê³  ê´€ë ¨ëœ ì•„ë˜ê°™ì€ ì—°êµ¬ê²°ê³¼ë¥¼ ê°™ì´ ë³´ì—¬ì¤€ë‹¤.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 1.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<p>Song Han êµìˆ˜ë‹˜ì€ Vision ë”¥ëŸ¬ë‹ ëª¨ë¸ ê²½ëŸ‰í™” ì—°êµ¬ë¥¼ ì£¼ë¡œí•˜ì…”ì„œ, CNNì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ëª¨ë¸ì„ ì˜ˆì‹œë¡œ ë³´ì—¬ì£¼ì‹ ë‹¤. ëª¨ë‘ Pruningì´í›„ì— ëª¨ë¸ ì‚¬ì´ì¦ˆì˜ ê²½ìš° ìµœëŒ€ 12ë°° ì¤„ì–´ ë“¤ë©° ì—°ì‚°ì˜ ê²½ìš° 6.3ë°°ê¹Œì§€ ì¤„ì–´ ë“  ê²ƒì„ ë³¼ ìˆ˜ ë‹¤.</p>
<p>ê·¸ë ‡ë‹¤ë©´ ì €ë ‡ê²Œ â€œ<strong>í¬ê¸°ê°€ ì¤„ì–´ë“  ëª¨ë¸ì´ ì„±ëŠ¥ì„ ìœ ì§€í•  ìˆ˜ ìˆì„ê¹Œ?â€œ</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 2.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<p>ê·¸ë˜í”„ì—ì„œ ëª¨ë¸ì˜ Weight ë¶„í¬ë„ë¥¼ ìœ„ ê·¸ë¦¼ì—ì„œ ë³´ë©´, Pruningì„ í•˜ê³  ë‚œ ì´í›„ì— Weight ë¶„í¬ë„ì˜ ì¤‘ì‹¬ì— íŒŒë¼ë¯¸í„°ê°€ ì˜ë ¤ë‚˜ê°„ ê²Œ ë³´ì¸ë‹¤. ì´í›„ Fine Tuningì„ í•˜ê³  ë‚œ ë‹¤ìŒì˜ ë¶„í¬ê°€ ë‚˜ì™€ ìˆëŠ”ë°, ì–´ëŠ ì •ë„ ì •í™•ë„ëŠ” ë–¨ì–´ì§€ì§€ë§Œ ì„±ëŠ¥ì´ ìœ ì§€ë˜ëŠ” ê±¸ ê´€ì°°í•  ìˆ˜ ìˆë‹¤.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 3.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<p>ê·¸ëŸ° Fine tuningì„ ë°˜ë³µì ìœ¼ë¡œ í•˜ê²Œ ëœë‹¤ë©´(Iterative Pruning and Fine tuning) ê·¸ë˜í”„ì—ì„œëŠ” ìµœëŒ€ 90í”„ë¡œ ì´ìƒì˜ íŒŒë¼ë¯¸í„°ë¥¼ ëœì–´ë‚¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.</p>
<p>ë¬¼ë¡  íŠ¹ì • ëª¨ë¸ì—ì„œ, íŠ¹ì • Taskë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ê²ƒì´ë¼ ì¼ë°˜í™”í•  ìˆ˜ëŠ” ì—†ì§€ë§Œ <strong>ë¦¬ì†ŒìŠ¤ë¥¼ ê³ ë ¤í•˜ëŠ” ìƒí™©</strong>ì´ë¼ë©´ ì¶©ë¶„íˆ ì‹œë„í•´ë³¼ ë§Œí•œ ê°€ì¹˜ê°€ ìˆì–´ ë³´ì¸ë‹¤. ê·¸ëŸ¼ ì´ë ‡ê²Œ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ Pruningì„ í•˜ê¸° ìœ„í•´ì„œ ì–´ë–¤ ìš”ì†Œë¥¼ ê³ ë ¤í•´ì•¼ í• ì§€ ë” ìì„¸íˆ ì´ì•¼ê¸°í•´ë³´ì!</p>
<p>ì†Œê°œí•˜ëŠ” ê³ ë ¤ìš”ì†ŒëŠ” ì•„ë˜ì™€ ê°™ë‹¤. Pruning íŒ¨í„´ë¶€í„° ì°¨ë¡€ëŒ€ë¡œ ì‹œì‘!</p>
<ul>
<li>Pruning Granularity â†’ Pruning íŒ¨í„´</li>
<li>Pruning Criterion â†’ ì–¼ë§ˆë§Œí¼ì— íŒŒë¼ë¯¸í„°ë¥¼ Pruning í•  ê±´ê°€?</li>
<li>Pruning Ratio â†’ ì „ì²´ íŒŒë¼ë¯¸í„°ì—ì„œ Pruningì„ ì–¼ë§ˆë§Œí¼ì˜ ë¹„ìœ¨ë¡œ?</li>
<li>Fine Turning â†’ Pruning ì´í›„ì— ì–´ë–»ê²Œ Fine-Tuning í•  ê±´ê°€?</li>
<li>ADMM â†’ Pruning ì´í›„, ì–´ë–»ê²Œ Convexê°€ ëœë‹¤ê³  í•  ìˆ˜ ìˆì§€?</li>
<li>Lottery Ticket Hypothesis â†’ Trainingë¶€í„° Pruningê¹Œì§€ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ì!</li>
<li>System Support â†’ í•˜ë“œì›¨ì–´ë‚˜ ì†Œí”„íŠ¸ì›¨ì–´ì ìœ¼ë¡œ Pruningì„ ì§€ì›í•˜ëŠ” ê²½ìš°ëŠ”?</li>
</ul>
</section>
<section id="determine-the-pruning-granularity" class="level2">
<h2 class="anchored" data-anchor-id="determine-the-pruning-granularity">2. Determine the Pruning Granularity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 4.png" class="img-fluid figure-img"></p>
<figcaption>The case of convolutional layers, red box is preserved and white one is pruned referred from MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<p>ì—¬ê¸°ì„œ ê³ ë ¤ìš”ì†ŒëŠ” â€œì–¼ë§ˆë§Œí¼ ë‰´ëŸ°ì„ ê·¸ë£¹í™”í•˜ì—¬ ê³ ë ¤í•  ê²ƒì¸ê°€?â€ ì…ë‹ˆë‹¤. Regularí•œ ì •ë¡œë„ ë¶„ë¥˜í•˜ë©´ì„œ Irregularí•œ ê²½ìš°ì™€ Regularí•œ ê²½ìš°ì˜ íŠ¹ì§•ì„ ì•„ë˜ì²˜ëŸ¼ ë§í•©ë‹ˆë‹¤.</p>
<ul>
<li>Fine-grained/Unstructured
<ul>
<li>More flexible pruning index choice</li>
<li>Hard to accelerate (irregular data expression)</li>
<li>Can deliver speed up on some custom hardware</li>
</ul></li>
<li>Coarse-grained/Structured
<ul>
<li>Less flexible pruning index choice (a subset of the fine-grained case)</li>
<li>Easy to accelerate</li>
</ul></li>
</ul>
<p>Pruningì„ í•œë‹¤ê³  ëª¨ë¸ ì¶œë ¥ì´ ë‚˜ì˜¤ëŠ” ì‹œê°„ì´ ì§§ì•„ì§€ëŠ” ê²ƒì´ ì•„ë‹˜ë„ ì–¸ê¸‰í•©ë‹ˆë‹¤. Hardware Accelerationì˜ ê°€ëŠ¥ë„ê°€ ìˆëŠ”ë°, ì´ íŠ¹ì§•ì„ ë³´ë©´ ì•Œ ìˆ˜ ìˆë“¯, Pruningì˜ ììœ ë„ì™€ Hardware Accelerationì´ trade-off, <strong>ì¦‰ ê²½ëŸ‰í™” ì •ë„ì™€ Latencyì‚¬ì´ì— trade-off</strong> ê°€ ìˆì„ ê²ƒì´ ì˜ˆì¸¡ë©ë‹ˆë‹¤. í•˜ë‚˜ì”©, ìë£Œë¥¼ ë³´ë©´ì„œ ì‚´í´ ë³´ê² ìŠµë‹ˆë‹¤.</p>
<section id="pattern-based-pruning" class="level3">
<h3 class="anchored" data-anchor-id="pattern-based-pruning">2.1 Pattern-based Pruning</h3>
<p>Irregularì—ì„œë„ Pattern-based Pruningì€ <strong>ì—°ì†ì ì¸ ë‰´ëŸ° Mê°œ ì¤‘ Nê°œë¥¼ Pruning í•˜ëŠ” ë°©ë²•ì´ë‹¤</strong>. ì¼ë°˜ì ìœ¼ë¡œëŠ” N:M = 2:4 ìœ¼ë¡œ í•œë‹¤ê³  ì†Œê°œí•œë‹¤.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 5.png" class="img-fluid figure-img"></p>
<figcaption>Reference. Accelerating Inference with Sparsity Using the NVIDIA Ampere Architecture and NVIDIA TensorRT</figcaption>
</figure>
</div>
<p>Reference. Accelerating Inference with Sparsity Using the NVIDIA Ampere Architecture and NVIDIA TensorRT</p>
<p>ì˜ˆì‹œë¥¼ ë“¤ì–´ ë³´ë©´, ìœ„ì™€ ê°™ì€ Matrixì—ì„œ í–‰ì„ ë³´ì‹œë©´ 8ê°œì˜ Weightì¤‘ 4ê°œê°€ Non-zeroì¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ Zeroì¸ ë¶€ë¶„ì„ ì—†ì• ê³  2bit indexë¡œ í•˜ì—¬ Matrix ì—°ì‚°ì„ í•˜ë©´ Nvidiaâ€™s Ampere GPUì—ì„œ ì†ë„ë¥¼ 2ë°°ê¹Œì§€ ë†’ì¼ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤. ì—¬ê¸°ì„œ <strong>Sparsity</strong>ëŠ” â€œì–¼ë§ˆë§Œí¼ ê²½ëŸ‰í™” ëëŠ”ì§€?â€ ì´ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤.</p>
<ul>
<li><strong>N:M sparsity</strong> means that in each <strong>contiguous M elements</strong>, <strong>N of them is pruned</strong></li>
<li>A classic case is 2:4 sparsity (50% sparsity)</li>
<li>It is supported by Nvidiaâ€™s Ampere GPU Architecture, which delivers up to 2x speed up and usually maintains accuracy.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 6.png" class="img-fluid figure-img"></p>
<figcaption>Reference. <a href="https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/">https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/</a></figcaption>
</figure>
</div>
</section>
<section id="channel-level-pruning" class="level3">
<h3 class="anchored" data-anchor-id="channel-level-pruning">2.2 Channel-level Pruning</h3>
<p>ë°˜ëŒ€ë¡œ íŒ¨í„´ì´ ìƒëŒ€ì ìœ¼ë¡œ regular í•œ ìª½ì¸ Channel-level Pruningì€ ì¶”ë¡ ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” ë°˜ë©´ì— ê²½ëŸ‰í™” ë¹„ìœ¨ì´ ì ë‹¤ê³  ë§í•œë‹¤. ì•„ë˜ ê·¸ë¦¼ì„ ë³´ì‹œë©´ Layerë§ˆë‹¤ Sparsityê°€ ë‹¤ë¥¸ ê±¸ ë³´ì‹¤ ìˆ˜ ìˆë‹¤.</p>
<ul>
<li>Pro: Direct speed up!</li>
<li>Con: smaller compression ratio</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 7.png" class="img-fluid figure-img"></p>
<figcaption>Reference AMC: Automl for Model Compression and Acceleration on Mobile Devices [He&nbsp;<em>et al.</em>, ECCV 2018]</figcaption>
</figure>
</div>
<p>ì•„ë˜ì— ìë£Œì—ì„œëŠ” Channel ë³„ë¡œ í•œ Pruningì˜ ê²½ìš° ì „ì²´ ë‰´ë ¨ì„ ê°€ì§€ê³  í•œ Pruningë³´ë‹¤ ì¶”ë¡  ì‹œê°„ì„ ë” ì¤„ì¼ ìˆ˜ ìˆë‹¤ê³  ë§í•œë‹¤.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 8.png" class="img-fluid figure-img"></p>
<figcaption>Reference AMC: Automl for Model Compression and Acceleration on Mobile Devices [He&nbsp;<em>et al.</em>, ECCV 2018]</figcaption>
</figure>
</div>
<p>ìë£Œë¥¼ ë³´ë©´ <strong>Sparsityì—ì„œëŠ” íŒ¨í„´í™” ë¼ ìˆìœ¼ë©´</strong> <strong>ê°€ì†í™”</strong>ê°€ ìš©ì´í•´ <strong>Latency, ì¶”ë¡  ì‹œê°„</strong>ì„ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ ê·¸ ë§Œí¼ Pruningí•˜ëŠ” ë‰´ëŸ°ì˜ ìˆ˜ê°€ ì ì–´ ê²½ëŸ‰í™” ë¹„ìœ¨ì´ ì¤„ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. í•˜ì§€ë§Œ <strong>ë¹„êµì  ë¶ˆê·œì¹™í•œ ìª½ì— ì†í•˜ëŠ” Pattern-based Pruningì˜ ê²½ìš°</strong>ê°€ <strong>í•˜ë“œì›¨ì–´ì—ì„œ ì§€ì›</strong>í•´ì£¼ëŠ” ê²½ìš°, <strong>ëª¨ë¸ í¬ê¸°ì™€ Latencyë¥¼ ë‘˜ ë‹¤</strong> ìµœì ìœ¼ë¡œ ì¡ì„ ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.</p>
</section>
</section>
<section id="determine-the-pruning-criterion" class="level2">
<h2 class="anchored" data-anchor-id="determine-the-pruning-criterion">3. Determine the Pruning Criterion</h2>
<p>ê·¸ë ‡ë‹¤ë©´ ì–´ë–¤ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ëŠ” ë‰´ëŸ°ì„ ìš°ë¦¬ëŠ” ì˜ë¼ë‚´ì•¼ í• ê¹Œìš”? Synapseì™€ Neuronìœ¼ë¡œ ë‚˜ëˆ ì„œ ì‚´í´ë³´ì.</p>
<ul>
<li>Which synapses? Which neurons? <strong>Which one is less important?</strong></li>
<li><strong>How to Select Synapses and Select Neurons to Prune</strong></li>
</ul>
<section id="select-of-synapses" class="level3">
<h3 class="anchored" data-anchor-id="select-of-synapses">3.1 <strong>Select of Synapses</strong></h3>
<p>í¬ê²Œ ì„¸ ê°€ì§€ë¡œ ë¶„ë¥˜í•˜ëŠ”ë°, ê° ë‰´ëŸ°ì˜ í¬ê¸°, ê° ì±„ë„ì— ì „ì²´ ë‰´ëŸ°ì— ëŒ€í•œ í¬ê¸°, ê·¸ë¦¬ê³  í…Œì¼ëŸ¬ ê¸‰ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ gradientì™€ weightë¥¼ ëª¨ë‘ ê³ ë ¤í•œ í¬ê¸°ë¥¼ ì†Œê°œí•œë‹¤. Song han êµìˆ˜ë‹˜ì´ ë°©ë²•ë“¤ì„ ì†Œê°œí•˜ê¸°ì— ì•ì„œì„œ ìœ ìˆ˜ì˜ ê¸°ì—…ë“¤ë„ ì§€ë‚œ 5ë…„ ë™ì•ˆ ì£¼ë¡œ <strong>Magnitude-based Pruning</strong>ë§Œì„ ì‚¬ìš©í•´ì™”ë‹¤ê³  í•˜ëŠ”ë°, 2023ë…„ì´ ë¼ì„œ On-device AIê°€ ê°ê´‘ë°›ê¸° ì‹œì‘í•´ì„œ ì ì°¨ì ìœ¼ë¡œ ê´€ì‹¬ì„ ë°›ê¸° ì‹œì‘í•œ ê±´ê°€ ì‹¶ê¸°ë„ í•˜ë‹¤.</p>
<p><strong>3.1.1 Magnitude-based Pruning</strong></p>
<p>í¬ê¸°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ëŠ” ê²½ìš°, <strong>â€œì–¼ë§ˆë§Œí¼ ë‰´ëŸ° ê·¸ë£¹ì—ì„œ ê³ ë ¤í•  ê²ƒì¸ê°€?â€</strong>ì™€ â€œê·¸ë£¹<strong>ë‚´ì—ì„œ ì–´ë–¤ ì •ê·œí™”ë¥¼ ì‚¬ìš©í•  ê²ƒì¸ê°€?</strong>ë¥¼ ê³ ë ¤í•œë‹¤.</p>
<ol type="1">
<li><p>Heuristic pruning criterion, Element-wise Pruning</p>
<p><span class="math display">\[
Importance = \lvert W \lvert
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 9.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div></li>
<li><p>Heuristic pruning criterion, Row-wise Pruning, L1-norm magnitude</p>
<p><span class="math display">\[
Importance = \sum_{i\in S}\lvert w_i \lvert, \\where\ W^{(S)}\ is\ the\ structural\ set\ S\ of\ parameters\ W
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 10.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div></li>
<li><p>Heuristic pruning criterion, Row-wise Pruning, L2-norm magnitude</p>
<p><span class="math display">\[
Importance = \sum_{i\in S}\lvert w_i \lvert, \\where\ W^{(S)}\ is\ the\ structural\ set\ S\ of\ parameters\ W
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 11.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div></li>
<li><p>Heuristic pruning criterion, <span class="math inline">\(L_p\)</span>- norm</p>
<p><span class="math display">\[
\lvert\lvert W^{(S)}\lvert\lvert=\huge( \large
   \sum_{i\in S} \lvert w_i \lvert^p
\huge) \large^{\frac{1}{p}}
\]</span></p></li>
</ol>
<p><strong>3.1.2 Scaling-based Pruning</strong></p>
<p>ë‘ ë²ˆì§¸ë¡œ Scalingì„ í•˜ëŠ” ê²½ìš° ì±„ë„ë§ˆë‹¤ Scaling Factorë¥¼ ë‘¬ì„œ Pruningì„ í•œë‹¤. ê·¸ëŸ¼ Scaling Factorë¥¼ ì–´ë–»ê²Œ ë‘¬ì•¼ í• ê¹Œ? ê°•ì˜ì—ì„œ ì†Œê°œí•˜ëŠ” <a href="https://arxiv.org/pdf/1708.06519.pdf">ì´ ë…¼ë¬¸</a>ì—ì„œëŠ” Scaling factor <span class="math inline">\(\gamma\)</span> íŒŒë¼ë¯¸í„°ë¥¼ trainable íŒŒë¼ë¯¸í„°ë¡œ ë‘ë©´ì„œ batch normalization layerì— ì‚¬ìš©í•œë‹¤.</p>
<ul>
<li><p>Scale factor is associated with each filter(i.e.&nbsp;output channel) in convolution layers.</p></li>
<li><p>The filters or output channels with small scaling factor magnitude will be pruned</p></li>
<li><p>The scaling factors can be reused from batch normalization layer</p>
<p><span class="math display">\[
  z_o = \gamma\dfrac{z_i-\mu_{B}}{\sqrt{\sigma_B^2+\epsilon}}+\beta
  \]</span></p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 12.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<p><strong>3.1.3 Talyor Expansion Analysis on Pruning Error</strong></p>
<p>ì„¸ ë²ˆì§¸ ë°©ë²•ì€ í…Œì¼ëŸ¬ ê¸‰ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ Objective functionì„ ìµœì†Œí™” í•˜ëŠ” ì§€ì ì„ ì°¾ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. Talyor Seriesì— ëŒ€í•œ <a href="https://ooshyun.github.io/2023/07/02/Taylor-Series-Approximation-and-Error.html">ìì„¸í•œ ë‚´ìš©</a>ì€ ì—¬ê¸°ì„œ!</p>
<ul>
<li>Evaluate pruning error induced by pruning synapses.</li>
<li>Minimize the objective function L(x; W)</li>
<li>A Taylor series can approximate the induced error.</li>
</ul>
<p><span class="math display">\[
\delta L = L(x;W)-L(x;W_p=W-\delta W) \\ = \sum_i g_i\delta w_i + \frac{1}{2} \sum_i h_{ii}\delta w_i^2 + \frac{1}{2}\sum_{i\not=j}h_{ij}\delta w_i \delta w_j + O(\lvert\lvert \delta W \lvert\lvert^3)
\]</span> <span class="math display">\[
where\ g_i=\dfrac{\delta L}{\delta w_i}, h_{i, j} = \dfrac{\delta^2 L}{\delta w_i \delta w_j}
\]</span></p>
<ol type="1">
<li><p>Second-Order-based Pruning</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 13.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 14.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<p>Optimal Brain Damage[LeCun&nbsp;<em>et al.,</em>&nbsp;NeurIPS 1989] ë…¼ë¬¸ì—ì„œëŠ” ì´ ë°©ë²•ì„ ì´ìš©í•˜ê¸° ìœ„í•´ ì„¸ ê°€ì§€ë¥¼ ê°€ì •í•œë‹¤.</p>
<ol type="1">
<li>Objective function Lì´ quadratic ì´ê¸° ë•Œë¬¸ì— ë§ˆì§€ë§‰ í•­ì´ ë¬´ì‹œëœë‹¤(ì´ëŠ” Talyor Seriesì˜ Error í•­ì„ ì•Œë©´ ì´í•´ê°€ ë” ì‰½ë‹¤!)</li>
<li>ë§Œì•½ ì‹ ê²½ë§ì´ ìˆ˜ë ´í•˜ê²Œë˜ë©´, ì²« ë²ˆì§¸í•­ë„ ë¬´ì‹œëœë‹¤.</li>
<li>ê° íŒŒë¼ë¯¸í„°ê°€ ë…ë¦½ì ì´ë¼ë©´ Cross-termë„ ë¬´ì‹œëœë‹¤.</li>
</ol>
<p>ê·¸ëŸ¬ë©´ ì‹ì„ ì•„ë˜ì²˜ëŸ¼ ì •ë¦¬í•  ìˆ˜ ìˆëŠ”ë°, ì¤‘ìš”í•œ ë¶€ë¶„ì€ <strong>Hessian Matrix Hì— ì‚¬ìš©í•˜ëŠ” Computationì´ ì–´ë µë‹¤ëŠ” ì !</strong></p>
<p><span class="math display">\[
\delta L_i = L(x;W)-L(x;W_p\lvert w_i=0)\approx \dfrac{1}{2} h_{ii}w_i^2,\ where\ h_{ii}=\dfrac{\partial^2 L}{\partial w_i \partial w_j}
\]</span></p>
<p><span class="math display">\[
importance_{w_i} = \lvert \delta L_i\lvert = \frac{1}{2}h_{ii}w_i^2
\]</span> <span class="math display">\[
*\ h_{ii} \text{ is non-negative}
\]</span></p></li>
<li><p>First-Order-based Pruning</p>
<ul>
<li>ì°¸ê³ ë¡œ ì´ ë°©ë²•ì€ 2023ë…„ì—ëŠ” ì†Œê°œí•˜ì§€ ì•ŠëŠ”ë‹¤.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 15.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<ul>
<li>If only first-order expansion is considered under an <em>i.i.d(</em>Independent and identically distributed<strong>)</strong> assumption,</li>
</ul>
<p><span class="math display">\[
\delta L_i = L(x;W) - L(x; W_P\lvert w_i=0) \approx g_iw_i,\ where\ g_i=\dfrac{\partial L}{\partial w_i}
\]</span> <span class="math display">\[
importance_{w_i} = \lvert \delta L_i \lvert = \lvert g_i w_i \lvert \ or \ importance_{w_i} = \lvert \delta L_i \lvert^2 = (g_i w_i)^2
\]</span></p>
<ul>
<li><p>For coarse-grained pruning, we have,</p>
<p><span class="math display">\[
  importance_{\ W^{(S)}} = \sum_{i \in S}\lvert \delta L_i \lvert^2 = \sum_{i \in S} (g_i w_i)^2,\ where \ W^{(S)}is\ the\ structural\ set\ of\ parameters
  \]</span></p></li>
</ul></li>
</ol>
</section>
<section id="select-of-neurons" class="level3">
<h3 class="anchored" data-anchor-id="select-of-neurons">3.2 <strong>Select of Neurons</strong></h3>
<p>ì–´ë–¤ Neuronì„ ì—†ì•¨ ì§€ë¥¼ ê³ ë ¤(<strong>Less useful â†’ Remove)</strong> í•œ ì´ ë°©ë²•ì€ <strong>Neuronì˜ ê²½ìš°</strong>ë„ ìˆì§€ë§Œ ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ <strong>Channel</strong>ë¡œ ê³ ë ¤í•  ìˆ˜ë„ ìˆë‹¤. í™•ì‹¤íˆ ì „ì— ì†Œê°œí–ˆë˜ ë°©ë²•ë“¤ë³´ë‹¤ <strong>â€œCoarse-grained pruningâ€</strong>ì¸ ë°©ë²•ì´ë‹¤.</p>
<p><img src="../../images/lec03/Untitled 16.png" class="img-fluid"></p>
<ol type="1">
<li><p>Percentage-of-Zero-based Pruning</p>
<p>ì²«ë²ˆì§¸ëŠ” Channelë§ˆë‹¤ 0ì˜ ë¹„ìœ¨ì„ ë´ì„œ ë¹„ìœ¨ì´ ë†’ì€ Channel ì„ ì—†ë‚´ëŠ” ë°©ë²•ì´ë‹¤. ReLU activationì„ ì‚¬ìš©í•˜ë©´ Outputì´ 0ì´ ë‚˜ì˜¤ëŠ”ë°, ì—¬ê¸°ì„œ 0ì˜ ë¹„ìœ¨, Average Percentage of Zero activations(APoZ)ë¼ê³  ë¶€ë¥´ëŠ” ê²ƒì„ ë³´ê³  ê°€ì§€ì¹˜ê¸°í•  Channelì„ ì œê±°í•œë‹¤.</p>
<ul>
<li>ReLU activation will generate zeros in the output activation</li>
<li>Similar to magnitude of weights, the Average Percentage of Zero activations(APoZ) can be exploited to measure the importance the neuron has</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 17.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div></li>
<li><p>First-Order-based Pruning</p>
<ul>
<li><p>ì°¸ê³ ë¡œ ì´ ë°©ë²•ì€ 2023ë…„ì—ëŠ” ì†Œê°œí•˜ì§€ ì•ŠëŠ” ë°©ë²•ì´ë‹¤.</p></li>
<li><p>Minimize the error on loss function introduced by pruning neurons</p></li>
<li><p>Similar to previous Taylor expansion on weights, the induced error of the objective function&nbsp;<em>L</em>(x;&nbsp;W)&nbsp;can be approximated by a Taylor series expanded on activations.</p>
<p><span class="math display">\[
  \delta L_i = L(x; W) - L(x\lvert x_i = 0; W) \approx \dfrac{\partial L}{\partial x_i}x_i
  \]</span></p></li>
<li><p>For a structural set of neurons&nbsp;<span class="math inline">\(x^{(S)}\)</span>&nbsp;(<em>e.g.</em>, a channel plane),</p>
<p><span class="math display">\[
  \lvert \delta L_{x^{(S)}} \lvert\ = \Large\lvert \small\sum_{i\in S}\dfrac{\partial L}{\partial x_i}x_i\Large\lvert
  \]</span></p></li>
</ul></li>
<li><p>Regression-based Pruning</p>
<p>ì´ ë°©ë²•ì€ Quantizedí•œ ë ˆì´ì–´ì˜ output <span class="math inline">\(\hat Z\)</span>(construction error of the corresponding layerâ€™s outputs)ì™€ <span class="math inline">\(Z\)</span>ë¥¼ Trainingì„ í†µí•´ ì°¨ì´ë¥¼ ì¤„ì´ëŠ” ë°©ë²•ì´ë‹¤. ì°¸ê³ ë¡œ ë¬¸ì œë¥¼ í‘¸ëŠ” ìì„¸í•œ ê³¼ì •ì€ 2022ë…„ ê°•ì˜ì—ë§Œ ë‚˜ì™€ ìˆë‹¤.</p></li>
</ol>
<p><span class="math display">\[
Z=XW^T=\sum_{c=0}^{c_i-1}X_cW_c^T
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/lec03/Untitled 18.png" class="img-fluid figure-img"></p>
<figcaption>Reference. MIT-TinyML-lecture03-Pruning-1</figcaption>
</figure>
</div>
<p>ë¬¸ì œë¥¼ ì‹ìœ¼ë¡œ ì •ì˜í•´ë³´ë©´ ì•„ë˜ì™€ ê°™ì€ë°,</p>
<ul>
<li><span class="math inline">\(\beta\)</span> is the coefficient vector of length <span class="math inline">\(c_i\)</span> for channel selection.</li>
<li><span class="math inline">\(\beta_c = 0\)</span> means channel <span class="math inline">\(c\)</span> is pruned.</li>
<li><span class="math inline">\(N_c\)</span> is the number of none zero channel</li>
</ul>
<p>ìš°ì„  ë¬¸ì œë¥¼ í‘¸ëŠ” ë‹¨ê³„ëŠ” ë‘ ë‹¨ê³„ë¡œ ë‚˜ëˆˆë‹¤. Channelì˜ Scale <span class="math inline">\(\beta\)</span>ë¥¼ ìš°ì„  ê³„ì‚°í•œ í›„ì— <span class="math inline">\(W\)</span>ë¥¼ Quantizedí•œ ë ˆì´ì–´ì˜ output <span class="math inline">\(\hat Z\)</span>(construction error of the corresponding layerâ€™s outputs)ì™€ <span class="math inline">\(Z\)</span>ì˜ ì°¨ì´ê°€ ìµœì†Œí™”ë˜ëŠ” ì§€ì ê¹Œì§€ Trainingì‹œí‚¨ë‹¤.</p>
<p>Solve the problem in two folds:</p>
<ul>
<li>Fix <strong>W,</strong> solve <span class="math inline">\(\beta\)</span> for channel selection â†’ <strong>NP(Nondeterministic polynomial)-hard</strong></li>
<li>Fix <strong><span class="math inline">\(\beta\)</span></strong>, solve W to minimize reconstruction error(<strong>Weight Reconstruction)</strong></li>
</ul>
<p>ê° ë¬¸ì œë¥¼ í‘¸ëŠ” ê³¼ì •ì„ ì¡°ê¸ˆ ë” ìì„¸íˆ ì‚´í´ë´ë³´ì. ë³¸ ë‚´ìš©ì€ 2022ë…„ ê°•ì˜ì— ìˆìœ¼ë‹ˆ ì°¸ê³ !</p>
<p><strong>NP(Nondeterministic polynomial)-hard</strong>ëŠ” ì•„ë˜ì™€ ê°™ì´ ì‹ìœ¼ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.</p>
<p><span class="math display">\[
\underset{\beta}{argmin} \lvert\lvert Z- \sum_{c=0}^{c_i-1} \beta_cX_cW_c^T \lvert\lvert_F^2 = \lvert\lvert \sum_{c=0}^{c_i-1}X_cW_c^T - \sum_{c=0}^{c_i-1} \beta_cX_cW_c^T \lvert\lvert_F^2
\]</span> <span class="math display">\[
= \lvert\lvert\sum_{c=0}^{c_i-1} (1-\beta_c)X_cW_c^T \lvert\lvert_F^2, \ s.t.\ \lvert\lvert\beta\lvert\lvert_0 \ \leq N_c
\]</span></p>
<p>ê°•ì˜ì—ì„œ ì†Œê°œí•˜ëŠ” ThiNetì´ë¼ëŠ” ë…¼ë¬¸ì—ì„œëŠ” greedy solutionì„ ì´ìš©í•´ì„œ ì±„ë„ í•˜ë‚˜í•˜ë‚˜ì”© Pruning í•´ë³´ë©° objective functionì˜ l2-norm ìµœì†Ÿê°’ì„ êµ¬í•œë‹¤.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="an">1:</span><span class="co"> S = []</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">2:</span><span class="co"> while len(S) &lt; N:</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">3:</span><span class="co">   min_norm, min_c = +inf, 0</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">4:</span><span class="co">   for c in range(c_i):</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">5:</span><span class="co">     tmpS=S+[c]</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="an">6:</span><span class="co">     Z = X[:,tmpS] * W[:,tmpS].t()</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="an">7:</span><span class="co">     norm = Z.norm(2)</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="an">8:</span><span class="co">     if norm &lt; min_norm:</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="an">9:</span><span class="co">       min_norm, min_c = norm, c</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="an">10:</span><span class="co">   S.append(min_c)</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="an">11:</span><span class="co">   c_i.pop(min_c)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>ì—¬ê¸°ì„œ ë”í•´ì„œ <span class="math inline">\(\beta\)</span> ë¥¼ êµ¬í•˜ëŠ” ê³¼ì •ì—ì„œ ì¼ë°˜í™”ë¥¼ ìœ„í•´ LASSO ë°©ì‹ì„ ì‚¬ìš©í•œë‹¤(LASSOì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ <a href="https://www.notion.so/Statistics-p-value-and-L1-L2-c5cabf858b194d8b9970eb88e739888e?pvs=21">ì—¬ê¸°ì„œ</a>). Relax the <span class="math inline">\(l_0\)</span> to <span class="math inline">\(l_1\)</span> regularization (LASSO):</p>
<p><span class="math display">\[
\underset{\beta}{argmin}\ \lvert\lvert Z- \sum_{c=0}^{c_i-1}\beta_cX_cW_c^T\lvert\lvert^2_F+\lambda\lvert\lvert \beta \lvert\lvert_1
\]</span></p>
<ul>
<li><p><span class="math inline">\(\lambda\)</span> is a penalty coefficient. <strong>By increasing <span class="math inline">\(\lambda\)</span>, there will be more zeros in <span class="math inline">\(\beta\)</span>.</strong></p></li>
<li><p>Gradually increase <span class="math inline">\(\lambda\)</span> and solve the LASSO regression for <span class="math inline">\(\beta\)</span>, until <span class="math inline">\(\lvert\lvert \beta \lvert\lvert_0==N_c\)</span> is met.</p></li>
<li><p>Why <span class="math inline">\(\lvert\lvert \beta \lvert\lvert_0==N_c\)</span>?</p>
<p>ì—¬ê¸°ì— ëŒ€í•´ì„œëŠ” ë”°ë¡œ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì§€ë§Œ, ì˜ë¯¸ìƒ scale ì „ì²´ Nê°œ ì¤‘ì—ì„œ ìµœì ê°’ì„ ì°¾ì•„ì•¼í•œë‹¤ë©´ ì „ì²´ë¥¼ Nìœ¼ë¡œ ìœ ì§€í•˜ë©´ì„œ ìµœì ê°’ì„ ì°¾ê¸° ìœ„í•´ì„œê°€ ì•„ë‹ê¹Œ?</p></li>
</ul>
<p>ë‘ ë²ˆì§¸ëŠ” êµ¬í•œ <span class="math inline">\(\beta\)</span>ë¥¼ ê³ ì •í•œ ìƒíƒœë¡œ Weightë¥¼ Quantized ì „í›„ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™” í•˜ê²Œ â€œWeight Reconstructionâ€ í•œë‹¤. êµ¬í•˜ëŠ” ê³¼ì •ì€ <strong>least square approach</strong>ë¥¼ ì´ìš©í•œ <strong>unique closed-form solution</strong> ì´ë¯€ë¡œ ì•„ë˜ë¥¼ ì°¸ì¡°í•˜ì.</p>
<p><span class="math display">\[
\underset{\beta}{argmin}\ \lvert\lvert Z- \sum_{c=0}^{c_i-1}\beta_cX_cW_c^T\lvert\lvert^2_F
\]</span></p>
<ul>
<li><p><span class="math inline">\(\beta\)</span> is a coefficient vector from the previous step</p></li>
<li><p>This is a classic <strong>linear regression problem</strong>, which has <strong>a unique closed-form solution</strong> using the <strong>least square</strong> approach.</p>
<p><span class="math display">\[
  \underset{W}{argmin} \lvert\lvert Z-\hat{Z} \lvert\lvert^2_F = \lvert\lvert Z-UW^T \lvert\lvert_F^2
  \]</span></p>
<p>where</p>
<p><span class="math display">\[
  U= \Large[ \small\beta_0X_0\ \beta_1X_1 \ \cdots \beta_cX_c \cdots \beta_{c_i-1}X_{c_i-1} \Large]
  \]</span></p>
<p>and thus,</p>
<p><span class="math display">\[
  W^T = (U^TU)^{-1}U^T Z
  \]</span></p>
<ul>
<li><p>Q. How <span class="math inline">\((U^TU)^{-1}\)</span> exists?</p>
<p>Least Square method, ì„ì˜ì˜ ë²¡í„° <span class="math inline">\(v = (v_0, v_1, \dots, v_n)\)</span> ê°€ ìˆì„ ë•Œ <span class="math inline">\(v^Tv\)</span> ì˜ ì—­í–‰ë ¬ì€ í•­ìƒ ìˆì„ê¹Œ? ê°€ì •ì—ì„œ â€œ<strong>a unique closed-form solution</strong>â€ë¼ê³  í–ˆìœ¼ë¯€ë¡œ ì´ëŠ” ì¦‰ linearly independenë¡œ ê³ ë ¤í•  ìˆê³  ì—­í–‰ë ¬ì´ ìˆë‹¤(<span class="math inline">\(v^Tv\)</span> is invertible)ëŠ” ì´ì•¼ê¸°ì´ë‹¤.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">4. Discussion</h2>
<ol type="1">
<li><p>Pruningì„ Dropoutì´ë‘ ë¹„êµí•´ì„œ ì–´ë–¤ ì°¨ì´ì ì´ ìˆëŠ”ê°€?</p>
<p>ë‘ ê°€ì§€ ë°©ë²•ì€ ë¶„ëª…íˆ Neuronê³¼ Synapseë¥¼ ì—†ëŒ„ë‹¤ëŠ” ì¸¡ë©´ì—ì„œëŠ” ë¹„ìŠ·í•˜ë‹¤. í•˜ì§€ë§Œ ë‘ ê°€ì§€ ì¸¡ë©´ì—ì„œ ì°¨ì´ì ì´ ìˆëŠ”ë°, í•œ ê°€ì§€ëŠ” ëª©ì í•˜ëŠ” ë°”ì´ê³ , ë‘ ë²ˆì§¸ëŠ” ì‹œì ì´ë‹¤. Dropoutì€ ëª©ì í•˜ëŠ” ë°”ê°€ í›ˆë ¨ì¤‘ì— overfittingì„ ë°©ì§€í•˜ê¸° ìœ„í•¨ì´ ìˆê³  Pruningì˜ ê²½ìš°ëŠ” <strong>í›ˆë ¨ì„ ë§ˆì¹œ ëª¨ë¸</strong>ì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì— ìˆë‹¤. ê·¸ë¦¬ê³  ë‘ ë²ˆì§¸ ì‹œì ì˜ ê²½ìš° Dropoutì€ í›ˆë ¨ì¤‘ì— ì´ë¤„ì§€ëŠ” ë°˜ë©´ Pruningì€ í›ˆë ¨ì„ ë§ˆì¹˜ê³ , ê·¸ í¬ê¸°ë¥¼ ì¤„ì¸ í›„ì— ì„±ëŠ¥ì´ ë–¨ì–´ì§€ë©´ ê·¸ì— ë§ê²Œ Fine-tuningì„ í•œë‹¤.</p>
<p>ìŠ¤í„°ë””ì—ì„œëŠ” â€œì™œ dropoutì„ í†µí•´ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì´ì§€ ì•Šì•˜ëŠ”ê°€? ê·¸ë¦¬ê³  êµ¬ì§€ í›ˆë ¨ì„ ë§ˆì¹œ ë‹¤ìŒì— í•  í•„ìš”ê°€ ìˆë‚˜?â€ ë¼ê³  ì§ˆë¬¸ì´ ë‚˜ì™”ì—ˆë‹¤. ë¬¼ë¡  í›ˆë ¨ ì¤‘ì— ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆë¥¼ ì‘ê²Œ ë§Œë“¤ ìˆ˜ ìˆìœ¼ë©´, ê°€ëŠ¥í•œ ê·¸ë ‡ê²Œ í•˜ë©´ ë  ê²ƒì´ë‹¤. í•˜ì§€ë§Œ, ì´ ë˜í•œ ë‘ê°€ì§€ ì¸¡ë©´ì„ ê³ ë ¤í•  í•„ìš”ê°€ ìˆë‹¤. í•˜ë‚˜ëŠ” â€œê³¼ì—° ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆë¥¼ í›ˆë ¨ ì¤‘ í˜¹ì€ ì „ì— ì¤„ì—¬ë‚˜ê°€ë©´ì„œ ì¶©ë¶„íˆ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆëŠ”ê°€?â€ì´ê³  ë‹¤ë¥¸ í•˜ë‚˜ëŠ” Pruningì´ë‚˜ ëª¨ë¸ ê²½ëŸ‰í™”ëŠ” <strong>ìµœì í™”ì— ì´ˆì </strong>ì„ ë§ì¶˜ë‹¤ê³  ìƒê°í•œë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— í›ˆë ¨ ì¤‘ê°„ì— Channel pruningê³¼ ê°™ì€ ê¸°ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ì§€ëŠ” ë¯¸ì§€ìˆ˜ì´ê³ , ì„¤ë ¹ Fine-grained Pruningê³¼ ê°™ì€ ê¸°ë²•ì„ ì‚¬ìš©í•œë‹¤ í•˜ë”ë¼ë„ ì´ëŠ” ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆë§Œ ì¤„ì–´ ë“¤ ë¿, ë‚˜ë¨¸ì§€ ë©”ëª¨ë¦¬(e.g.&nbsp;RAM)ì´ë‚˜ Latencyê°™ì€ ì„±ëŠ¥ì€ ì¢‹ê²Œ ê°€ì ¸ê°ˆ ìˆ˜ ìˆì„ì§€ë„ ë¯¸ì§€ìˆ˜ë¼ê³  ìƒê°í•œë‹¤.</p>
<p>í•„ìëŠ” ìœ„ì™€ ê°™ì€ ìµœì í™”ë¥¼ í†µí•œ ì„±ëŠ¥ ê°œì„ ì„ <a href="https://ooshyun.github.io/2023/12/04/Optimization-for-tiny-engine-1.html">ì´ ê¸€</a>ì—ì„œì²˜ëŸ¼ 2022ë…„ TinyML ê°•ì˜ì—ì„œ ì œê³µí•˜ëŠ” ì‹¤ìŠµì„ í†µí•´ ê²½í—˜í–ˆì—ˆë‹¤. ì•ì„  ì˜ˆì‹œëŠ” OSë¥¼ ê°€ì§„ ë””ë°”ì´ìŠ¤ê°€ ì•„ë‹Œ Bare-metal firmwareë¡œ í™˜ê²½ì´ ì¡°ê¸ˆ íŠ¹ìˆ˜í•˜ê¸°ë„ í•˜ê³ , ì‹¤ì œë¡œ Torchë‚˜ Tensorflowliteì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë¸ ê²½ëŸ‰í™”ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ë¶„ì„í•´ë´ì•¼ ì‹¤ì§ˆì ì¸ ì˜ˆì‹œë¥¼ ì•Œ ìˆ˜ ìˆê² ì§€ë§Œ, í˜¹ì—¬ ì´í•´í•´ ì°¸ê³ ê°€ ë ê¹Œ ë§ë¶™ì—¬ ë†“ëŠ”ë‹¤.</p></li>
</ol>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">5. Reference</h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=w5WiUcDJosM&amp;list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB&amp;index=5">MIT-TinyML-lecture03-Pruning-1</a></li>
<li><a href="https://arxiv.org/pdf/1802.03494.pdf">AMC: Automl for Model Compression and Acceleration on Mobile Devices, 2018</a></li>
<li><a href="https://arxiv.org/pdf/1708.06519.pdf">Learning Efficient Convolutional Networks through Network Slimming, 2017</a></li>
<li><a href="https://arxiv.org/pdf/1707.06342.pdf">ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression, 2017</a></li>
<li><a href="https://arxiv.org/pdf/1707.06168.pdf">Channel Pruning for Accelerating Very Deep Neural Networks</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="TINYML-KOR/blog" data-repo-id="R_kgDOLC9iGA" data-category="General" data-category-id="DIC_kwDOLC9iGM4Cc7eP" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->




</body></html>